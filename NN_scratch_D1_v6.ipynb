{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 \t Train Loss: 0.693147173558066\n",
            "Epoch:1000 \t Train Loss: 0.07601631295222705\n",
            "Epoch:2000 \t Train Loss: 0.07592969839148893\n",
            "Epoch:3000 \t Train Loss: 0.0759206246349953\n",
            "Epoch:4000 \t Train Loss: 0.07591735740097315\n",
            "Epoch:5000 \t Train Loss: 0.07591570491188152\n",
            "Epoch:6000 \t Train Loss: 0.07591472215782778\n",
            "Epoch:7000 \t Train Loss: 0.07591407442290293\n",
            "Epoch:8000 \t Train Loss: 0.07591361723052961\n",
            "Epoch:9000 \t Train Loss: 0.0759132783826496\n",
            "\n",
            "TRAINING RESULTS:\n",
            "Accuracy: 0.9978021978021978\n",
            "Precision: 0.9965156794425087\n",
            "Recall: 1.0\n",
            "F-1 Score: 0.9982547993019197\n",
            "\n",
            "TEST RESULTS:\n",
            "Loss:0.4221440532705125\n",
            "Accuracy: 0.9824561403508771\n",
            "Precision: 0.9859154929577465\n",
            "Recall: 0.9859154929577465\n",
            "F-1 Score: 0.9859154929577465\n",
            " \n",
            "Total Learnable Parameters: 541\n",
            "Peak RAM usage: 0.78 MB\n"
          ]
        }
      ],
      "source": [
        "#Four Layers, Ten neurons, ReLU in hidden layers, sigmoid in output layer\n",
        "# learning rate = 0.01 , epoch = 10000\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import tracemalloc\n",
        "\n",
        "tracemalloc.start()\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_test = y_test.reshape(-1,1)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "n_in = 30\n",
        "n_out = 10\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "W1 = np.random.randn(n_in, n_out) * 0.01\n",
        "b1 = np.zeros((1, n_out))\n",
        "\n",
        "W2 = np.random.randn(n_out, n_out) * 0.01\n",
        "b2 = np.zeros((1, n_out))\n",
        "\n",
        "W3 = np.random.randn(n_out, n_out) * 0.01\n",
        "b3 = np.zeros((1, n_out))\n",
        "\n",
        "W4 = np.random.randn(n_out, 1) * 0.01\n",
        "b4 = np.zeros((1, 1))\n",
        "\n",
        "def sigmoid(x):\n",
        "    x = np.clip(x, -500, 500)\n",
        "    return 1 / (1+np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    s = sigmoid(x)\n",
        "    return s * (1-s)\n",
        "\n",
        "def tanh(x):\n",
        "    return ( (np.exp(x)-np.exp(-x)) / (np.exp(x)+np.exp(-x)) )\n",
        "\n",
        "def tanh_derivative(x):\n",
        "    t = tanh(x)\n",
        "    return 1 - t**2\n",
        "\n",
        "def ReLU(x):\n",
        "    return np.maximum(0,x)\n",
        "\n",
        "def ReLU_derivative(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "def binary_cross_entropy(y, y_pred):\n",
        "    epsilon = 1e-15  \n",
        "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "    return (-1 / len(y_pred)) * np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
        "\n",
        "def loss_derivative(y, y_pred):\n",
        "    epsilon = 1e-8  \n",
        "    return -((y / (y_pred + epsilon)) - ((1 - y) / (1 - y_pred + epsilon)))\n",
        "\n",
        "def Forward_Propagation(X_train, W1, W2, W3, W4, b1, b2, b3, b4):\n",
        "\n",
        "    Z1 = np.dot(X_train, W1) + b1\n",
        "    A1 = ReLU(Z1)\n",
        "\n",
        "    Z2 = np.dot(A1, W2) + b2\n",
        "    A2 = ReLU(Z2)\n",
        "\n",
        "    Z3 = np.dot(A2, W3) + b3\n",
        "    A3 = ReLU(Z3)\n",
        "\n",
        "    Z4 = np.dot(A3, W4) + b4\n",
        "    y_pred = sigmoid(Z4)\n",
        "\n",
        "    return Z1, A1, Z2, A2, Z3, A3, Z4, y_pred\n",
        "\n",
        "\n",
        "def Backward_Propagation(A1, A2, A3, y_pred, Z1, Z2, Z3, Z4, y_train,\n",
        "                         learning_rate, W1, W2, W3, W4, b1, b2, b3, b4, X_train):\n",
        "\n",
        "    dA4 = loss_derivative(y_train, y_pred)\n",
        "    dZ4 = dA4 * sigmoid_derivative(Z4)\n",
        "    dW4 = np.dot(A3.T, dZ4)\n",
        "    db4 = np.sum(dZ4, axis=0, keepdims=True)\n",
        "\n",
        "    dA3 = np.dot(dZ4, W4.T)\n",
        "    dZ3 = dA3 * ReLU_derivative(Z3)\n",
        "    dW3 = np.dot(A2.T, dZ3)\n",
        "    db3 = np.sum(dZ3, axis=0, keepdims=True)\n",
        "\n",
        "    dA2 = np.dot(dZ3, W3.T)\n",
        "    dZ2 = dA2 * ReLU_derivative(Z2)\n",
        "    dW2 = np.dot(A1.T, dZ2)\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
        "\n",
        "    dA1 = np.dot(dZ2, W2.T)\n",
        "    dZ1 = dA1 * ReLU_derivative(Z1)\n",
        "    dW1 = np.dot(X_train.T, dZ1)\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
        "\n",
        "    W4 -= learning_rate * dW4\n",
        "    b4 -= learning_rate * db4\n",
        "\n",
        "    W3 -= learning_rate * dW3\n",
        "    b3 -= learning_rate * db3\n",
        "\n",
        "    W2 -= learning_rate * dW2\n",
        "    b2 -= learning_rate * db2\n",
        "\n",
        "    W1 -= learning_rate * dW1\n",
        "    b1 -= learning_rate * db1\n",
        "\n",
        "    return W4, W3, W2, W1, b4, b3, b2, b1\n",
        "\n",
        "\n",
        "# TRAIN\n",
        "learning_rate = 0.01\n",
        "n_epoch = 10000\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "\n",
        "    Z1, A1, Z2, A2, Z3, A3, Z4, y_pred = Forward_Propagation(X_train, W1, W2, W3, W4, b1, b2, b3, b4)\n",
        "    loss = binary_cross_entropy(y_train, y_pred)\n",
        "    W4, W3, W2, W1, b4, b3, b2, b1 = Backward_Propagation(A1, A2, A3, y_pred, Z1, Z2, Z3, Z4, y_train,learning_rate, W1, W2, W3, W4, b1, b2, b3, b4, X_train)\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch:{epoch} \\t Train Loss: {loss}\")\n",
        "\n",
        "\n",
        "y_train = y_train.flatten()\n",
        "y_pred = (y_pred > 0.5).astype(int).flatten()\n",
        "print(\"\\nTRAINING RESULTS:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_train,y_pred)}\")\n",
        "print(f\"Precision: {precision_score(y_train,y_pred)}\")\n",
        "print(f\"Recall: {recall_score(y_train,y_pred)}\")\n",
        "print(f\"F-1 Score: {f1_score(y_train,y_pred)}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#TEST\n",
        "\n",
        "Z1,A1,Z2,A2,Z3,A3,Z4,y_pred = Forward_Propagation(X_test,W1,W2,W3,W4,b1,b2,b3,b4)\n",
        "loss = binary_cross_entropy(y_test, y_pred)\n",
        "y_test = y_test.flatten()\n",
        "y_pred = (y_pred > 0.5).astype(int).flatten()\n",
        "print(\"\\nTEST RESULTS:\")\n",
        "print(f\"Loss:{loss}\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test,y_pred)}\")\n",
        "print(f\"Precision: {precision_score(y_test,y_pred)}\")\n",
        "print(f\"Recall: {recall_score(y_test,y_pred)}\")\n",
        "print(f\"F-1 Score: {f1_score(y_test,y_pred)}\")\n",
        "\n",
        "\n",
        "# LEARNABLE PARAMETERS\n",
        "\n",
        "def Total_Learnable_Parameters(W1,W2,W3,W4,b1,b2,b3,b4):\n",
        "    sum = 0\n",
        "\n",
        "    sum += W1.size\n",
        "    sum += W2.size\n",
        "    sum += W3.size\n",
        "    sum += W4.size\n",
        "    sum += b1.size\n",
        "    sum += b2.size\n",
        "    sum += b3.size\n",
        "    sum += b4.size\n",
        "\n",
        "    return sum\n",
        "\n",
        "print(f\" \\nTotal Learnable Parameters: {Total_Learnable_Parameters(W1,W2,W3,W4,b1,b2,b3,b4)}\")\n",
        "\n",
        "\n",
        "current, peak = tracemalloc.get_traced_memory()\n",
        "print(f\"Peak RAM usage: {peak / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "tracemalloc.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
