{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e164783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required library\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset from UCI ML Repository\n",
    "recipe_reviews_and_user_feedback = fetch_ucirepo(id=911)\n",
    "\n",
    "# Get features and target\n",
    "X = recipe_reviews_and_user_feedback.data.features\n",
    "y = recipe_reviews_and_user_feedback.data.targets\n",
    "\n",
    "# Combine features and target for easier inspection\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Display the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4fa8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Dataset shape (rows, columns)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "\n",
    "# Column names\n",
    "print(\"\\nColumns:\\n\", df.columns.tolist())\n",
    "\n",
    "# Data types\n",
    "print(\"\\nData types:\\n\", df.dtypes)\n",
    "\n",
    "# Missing value analysis\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Target variable distribution\n",
    "print(\"\\nTarget variable (stars) distribution:\\n\", df['stars'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable\n",
    "target = 'stars'\n",
    "\n",
    "# Review all columns\n",
    "print(\"All columns:\\n\", df.columns.tolist())\n",
    "\n",
    "# Columns to drop: identifiers, text, timestamps, etc.\n",
    "drop_columns = ['recipe_number', 'recipe_code', 'recipe_name', 'comment_id', 'user_id', \n",
    "                'user_name', 'created_at', 'text']  # dropping unstructured text etc.\n",
    "\n",
    "# Create new DataFrame without dropped columns\n",
    "df_cleaned = df.drop(columns=drop_columns)\n",
    "\n",
    "# Check new column set\n",
    "print(\"\\nRemaining columns:\\n\", df_cleaned.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_cleaned.drop(columns=[target])\n",
    "y = df_cleaned[target]\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool', 'category']).columns.tolist()\n",
    "\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n",
    "# Define transformers\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc29ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y  # preserve class distribution\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "\n",
    "# Apply preprocessing to training data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Apply the same transformation to test data\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5188c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the target variable (stars)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x=y)\n",
    "plt.title('Distribution of Stars (Target)')\n",
    "plt.xlabel('Star Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Relationship: thumbs_up vs. stars\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=y, y=df_cleaned['thumbs_up'])\n",
    "plt.title('Thumbs Up by Star Rating')\n",
    "plt.xlabel('Stars')\n",
    "plt.ylabel('Number of Thumbs Up')\n",
    "plt.show()\n",
    "\n",
    "# Relationship: reply_count vs. stars\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=y, y=df_cleaned['reply_count'])\n",
    "plt.title('Reply Count by Star Rating')\n",
    "plt.xlabel('Stars')\n",
    "plt.ylabel('Number of Replies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d5f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessing and visualization steps completed successfully.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
