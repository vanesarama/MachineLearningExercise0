{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The dataset contains MRI images of brain tumors, organized into Training and Testing directories with subdirectories for each class (e.g., glioma, meningioma, etc.). The workflow includes:\n",
    "\n",
    "- **Step 1**: Explore the dataset (class distribution).\n",
    "- **Step 2**: Load grayscale images and flatten them for Random Forest.\n",
    "- **Step 3**: Preprocess data (scaling, PCA for dimensionality reduction).\n",
    "- **Step 4**: Run Random Forest experiments with a parameter grid.\n",
    "- **Step 5**: Visualize results (confusion matrix, parameter effects).\n",
    "- **Step 6**: Compare holdout vs. cross-validation accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Directory Definitions\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define data directories\n",
    "data_dir = \"/Users/van/Desktop/TumorData\"  # Local dataset path\n",
    "train_dir = os.path.join(data_dir, \"Training\")\n",
    "test_dir = os.path.join(data_dir, \"Testing\")\n",
    "output_dir = \"/Users/van/Desktop/untitled folder/MachineLearningExercise0/BrainTumor\"  # Local output directory\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Exploration (/Users/van/Desktop/TumorData/Training):\n",
      "Classes and counts: {'no_tumor': 395, 'meningioma_tumor': 822, 'glioma_tumor': 826, 'pituitary_tumor': 827}\n",
      "Total images: 2870\n",
      "\n",
      "Dataset Exploration (/Users/van/Desktop/TumorData/Testing):\n",
      "Classes and counts: {'no_tumor': 105, 'meningioma_tumor': 115, 'glioma_tumor': 100, 'pituitary_tumor': 74}\n",
      "Total images: 394\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Step 1 - Explore Dataset\n",
    "def explore_dataset(dataset_path):\n",
    "    \"\"\"Explore dataset structure and class distribution.\"\"\"\n",
    "    class_counts = {}\n",
    "    for class_dir in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            class_counts[class_dir] = len(os.listdir(class_path))\n",
    "    \n",
    "    print(f\"\\nDataset Exploration ({dataset_path}):\")\n",
    "    print(f\"Classes and counts: {class_counts}\")\n",
    "    print(f\"Total images: {sum(class_counts.values())}\")\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()))\n",
    "    plt.title(f\"Class Distribution in {os.path.basename(dataset_path)}\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Number of Images\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(os.path.join(output_dir, f'class_distribution_{os.path.basename(dataset_path)}.png'))\n",
    "    plt.close()\n",
    "\n",
    "explore_dataset(train_dir)\n",
    "explore_dataset(test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n",
      "Training samples: 2870, Features: 16384\n",
      "Testing samples: 394\n",
      "Class names: ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Step 2 - Load Data\n",
    "def load_images_from_folder(folder_path, img_size=128):\n",
    "    \"\"\"Load grayscale images and labels for Random Forest using Pillow.\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = [label for label in sorted(os.listdir(folder_path)) if os.path.isdir(os.path.join(folder_path, label))]\n",
    "    label_map = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "    for label in labels:\n",
    "        class_folder = os.path.join(folder_path, label)\n",
    "        if not os.path.isdir(class_folder):\n",
    "            continue\n",
    "        for file in os.listdir(class_folder):\n",
    "            img_path = os.path.join(class_folder, file)\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('L')  # 'L' for grayscale\n",
    "                img = img.resize((img_size, img_size))\n",
    "                img_array = np.array(img).flatten()  # Convert to NumPy array and flatten\n",
    "                X.append(img_array)\n",
    "                y.append(label_map[label])\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y, labels\n",
    "\n",
    "# Load data with checkpointing\n",
    "print(\"\\nLoading data...\")\n",
    "train_data_path = os.path.join(output_dir, \"train_data_rf.npz\")\n",
    "test_data_path = os.path.join(output_dir, \"test_data_rf.npz\")\n",
    "\n",
    "if os.path.exists(train_data_path) and os.path.exists(test_data_path):\n",
    "    print(\"Loading saved data...\")\n",
    "    train_data = np.load(train_data_path)\n",
    "    test_data = np.load(test_data_path)\n",
    "    X_train, y_train = train_data['X'], train_data['y']\n",
    "    X_test, y_test = test_data['X'], test_data['y']\n",
    "    class_names = list(train_data['class_names'])\n",
    "else:\n",
    "    X_train, y_train, class_names = load_images_from_folder(train_dir)\n",
    "    X_test, y_test, _ = load_images_from_folder(test_dir)\n",
    "    np.savez(train_data_path, X=X_train, y=y_train, class_names=class_names)\n",
    "    np.savez(test_data_path, X=X_test, y=y_test)\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Features: {X_train.shape[1]}\")\n",
    "print(f\"Testing samples: {X_test.shape[0]}\")\n",
    "print(f\"Class names: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing with n_components=100\n",
      "\n",
      "Checking for missing values...\n",
      "No missing values found.\n",
      "Checking for outliers...\n",
      "No outliers found in pixel values.\n",
      "Applying PCA with 100 components...\n",
      "Explained variance ratio: 0.72\n",
      "\n",
      "Preprocessing with n_components=200\n",
      "\n",
      "Checking for missing values...\n",
      "No missing values found.\n",
      "Checking for outliers...\n",
      "No outliers found in pixel values.\n",
      "Applying PCA with 200 components...\n",
      "Explained variance ratio: 0.82\n",
      "\n",
      "Preprocessing with n_components=300\n",
      "\n",
      "Checking for missing values...\n",
      "No missing values found.\n",
      "Checking for outliers...\n",
      "No outliers found in pixel values.\n",
      "Applying PCA with 300 components...\n",
      "Explained variance ratio: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Step 3 - Preprocess Data\n",
    "def preprocess_data(X_train, X_test, n_components=100):\n",
    "    \"\"\"Scale data and apply PCA.\"\"\"\n",
    "    print(\"\\nChecking for missing values...\")\n",
    "    if np.any(np.isnan(X_train)) or np.any(np.isnan(X_test)):\n",
    "        print(\"Warning: Missing values detected. Consider imputation.\")\n",
    "    else:\n",
    "        print(\"No missing values found.\")\n",
    "    \n",
    "    print(\"Checking for outliers...\")\n",
    "    if np.any(X_train < 0) or np.any(X_train > 255) or np.any(X_test < 0) or np.any(X_test > 255):\n",
    "        print(\"Warning: Pixel values outside [0, 255] detected.\")\n",
    "    else:\n",
    "        print(\"No outliers found in pixel values.\")\n",
    "    \n",
    "    X_train_scaled = X_train / 255.0\n",
    "    X_test_scaled = X_test / 255.0\n",
    "    \n",
    "    print(f\"Applying PCA with {n_components} components...\")\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "    print(f\"Explained variance ratio: {sum(pca.explained_variance_ratio_):.2f}\")\n",
    "    \n",
    "    return X_train_pca, X_test_pca\n",
    "\n",
    "n_components_list = [100, 200, 300]\n",
    "pca_data = {}\n",
    "\n",
    "for n_components in n_components_list:\n",
    "    pca_path = os.path.join(output_dir, f\"pca_data_rf_{n_components}.npz\")\n",
    "    if os.path.exists(pca_path):\n",
    "        print(f\"Loading saved PCA data for n_components={n_components}...\")\n",
    "        data = np.load(pca_path)\n",
    "        pca_data[n_components] = (data['X_train_pca'], data['X_test_pca'])\n",
    "    else:\n",
    "        print(f\"\\nPreprocessing with n_components={n_components}\")\n",
    "        X_train_pca, X_test_pca = preprocess_data(X_train, X_test, n_components=n_components)\n",
    "        pca_data[n_components] = (X_train_pca, X_test_pca)\n",
    "        np.savez(pca_path, X_train_pca=X_train_pca, X_test_pca=X_test_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running 32 experiments for n_components=100...\n",
      "Experiment 1/32: n_estimators=50, max_depth=None, min_samples_split=2, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.75, F1-Score: 0.70, ROC-AUC: 0.95, CV Accuracy: 0.82\n",
      "Training Time: 2.53s, Prediction Time: 0.06s\n",
      "Experiment 2/32: n_estimators=50, max_depth=None, min_samples_split=2, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.75, F1-Score: 0.71, ROC-AUC: 0.93, CV Accuracy: 0.82\n",
      "Training Time: 1.09s, Prediction Time: 0.03s\n",
      "Experiment 3/32: n_estimators=50, max_depth=None, min_samples_split=2, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.77, F1-Score: 0.73, ROC-AUC: 0.95, CV Accuracy: 0.81\n",
      "Training Time: 0.68s, Prediction Time: 0.03s\n",
      "Experiment 4/32: n_estimators=50, max_depth=None, min_samples_split=2, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.75, F1-Score: 0.70, ROC-AUC: 0.95, CV Accuracy: 0.82\n",
      "Training Time: 0.68s, Prediction Time: 0.03s\n",
      "Experiment 5/32: n_estimators=50, max_depth=None, min_samples_split=5, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.78, F1-Score: 0.73, ROC-AUC: 0.95, CV Accuracy: 0.81\n",
      "Training Time: 1.06s, Prediction Time: 0.03s\n",
      "Experiment 6/32: n_estimators=50, max_depth=None, min_samples_split=5, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.73, F1-Score: 0.68, ROC-AUC: 0.92, CV Accuracy: 0.81\n",
      "Training Time: 1.00s, Prediction Time: 0.03s\n",
      "Experiment 7/32: n_estimators=50, max_depth=None, min_samples_split=5, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.75, F1-Score: 0.70, ROC-AUC: 0.94, CV Accuracy: 0.81\n",
      "Training Time: 0.68s, Prediction Time: 0.03s\n",
      "Experiment 8/32: n_estimators=50, max_depth=None, min_samples_split=5, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.77, F1-Score: 0.72, ROC-AUC: 0.94, CV Accuracy: 0.81\n",
      "Training Time: 0.69s, Prediction Time: 0.03s\n",
      "Experiment 9/32: n_estimators=50, max_depth=10, min_samples_split=2, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.74, F1-Score: 0.70, ROC-AUC: 0.91, CV Accuracy: 0.78\n",
      "Training Time: 0.77s, Prediction Time: 0.04s\n",
      "Experiment 10/32: n_estimators=50, max_depth=10, min_samples_split=2, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.74, F1-Score: 0.70, ROC-AUC: 0.90, CV Accuracy: 0.78\n",
      "Training Time: 0.75s, Prediction Time: 0.03s\n",
      "Experiment 11/32: n_estimators=50, max_depth=10, min_samples_split=2, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.74, F1-Score: 0.69, ROC-AUC: 0.90, CV Accuracy: 0.78\n",
      "Training Time: 0.57s, Prediction Time: 0.03s\n",
      "Experiment 12/32: n_estimators=50, max_depth=10, min_samples_split=2, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.75, F1-Score: 0.70, ROC-AUC: 0.89, CV Accuracy: 0.78\n",
      "Training Time: 0.53s, Prediction Time: 0.03s\n",
      "Experiment 13/32: n_estimators=50, max_depth=10, min_samples_split=5, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.73, F1-Score: 0.69, ROC-AUC: 0.90, CV Accuracy: 0.78\n",
      "Training Time: 0.74s, Prediction Time: 0.03s\n",
      "Experiment 14/32: n_estimators=50, max_depth=10, min_samples_split=5, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.71, F1-Score: 0.67, ROC-AUC: 0.90, CV Accuracy: 0.77\n",
      "Training Time: 0.77s, Prediction Time: 0.04s\n",
      "Experiment 15/32: n_estimators=50, max_depth=10, min_samples_split=5, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.74, F1-Score: 0.69, ROC-AUC: 0.90, CV Accuracy: 0.77\n",
      "Training Time: 0.52s, Prediction Time: 0.03s\n",
      "Experiment 16/32: n_estimators=50, max_depth=10, min_samples_split=5, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.70, F1-Score: 0.65, ROC-AUC: 0.89, CV Accuracy: 0.77\n",
      "Training Time: 0.51s, Prediction Time: 0.03s\n",
      "Experiment 17/32: n_estimators=100, max_depth=None, min_samples_split=2, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.76, F1-Score: 0.71, ROC-AUC: 0.96, CV Accuracy: 0.82\n",
      "Training Time: 1.98s, Prediction Time: 0.05s\n",
      "Experiment 18/32: n_estimators=100, max_depth=None, min_samples_split=2, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.77, F1-Score: 0.73, ROC-AUC: 0.94, CV Accuracy: 0.83\n",
      "Training Time: 2.20s, Prediction Time: 0.06s\n",
      "Experiment 19/32: n_estimators=100, max_depth=None, min_samples_split=2, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.78, F1-Score: 0.72, ROC-AUC: 0.95, CV Accuracy: 0.83\n",
      "Training Time: 1.38s, Prediction Time: 0.05s\n",
      "Experiment 20/32: n_estimators=100, max_depth=None, min_samples_split=2, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.77, F1-Score: 0.72, ROC-AUC: 0.95, CV Accuracy: 0.83\n",
      "Training Time: 1.26s, Prediction Time: 0.05s\n",
      "Experiment 21/32: n_estimators=100, max_depth=None, min_samples_split=5, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.78, F1-Score: 0.73, ROC-AUC: 0.95, CV Accuracy: 0.83\n",
      "Training Time: 1.98s, Prediction Time: 0.04s\n",
      "Experiment 22/32: n_estimators=100, max_depth=None, min_samples_split=5, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.76, F1-Score: 0.71, ROC-AUC: 0.94, CV Accuracy: 0.82\n",
      "Training Time: 1.98s, Prediction Time: 0.05s\n",
      "Experiment 23/32: n_estimators=100, max_depth=None, min_samples_split=5, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.76, F1-Score: 0.71, ROC-AUC: 0.95, CV Accuracy: 0.83\n",
      "Training Time: 1.30s, Prediction Time: 0.04s\n",
      "Experiment 24/32: n_estimators=100, max_depth=None, min_samples_split=5, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.76, F1-Score: 0.71, ROC-AUC: 0.94, CV Accuracy: 0.82\n",
      "Training Time: 1.26s, Prediction Time: 0.04s\n",
      "Experiment 25/32: n_estimators=100, max_depth=10, min_samples_split=2, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.75, F1-Score: 0.71, ROC-AUC: 0.92, CV Accuracy: 0.79\n",
      "Training Time: 1.47s, Prediction Time: 0.04s\n",
      "Experiment 26/32: n_estimators=100, max_depth=10, min_samples_split=2, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.75, F1-Score: 0.71, ROC-AUC: 0.90, CV Accuracy: 0.79\n",
      "Training Time: 1.41s, Prediction Time: 0.04s\n",
      "Experiment 27/32: n_estimators=100, max_depth=10, min_samples_split=2, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.74, F1-Score: 0.69, ROC-AUC: 0.90, CV Accuracy: 0.78\n",
      "Training Time: 0.99s, Prediction Time: 0.04s\n",
      "Experiment 28/32: n_estimators=100, max_depth=10, min_samples_split=2, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.75, F1-Score: 0.71, ROC-AUC: 0.89, CV Accuracy: 0.79\n",
      "Training Time: 0.96s, Prediction Time: 0.05s\n",
      "Experiment 29/32: n_estimators=100, max_depth=10, min_samples_split=5, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.75, F1-Score: 0.71, ROC-AUC: 0.90, CV Accuracy: 0.78\n",
      "Training Time: 1.51s, Prediction Time: 0.04s\n",
      "Experiment 30/32: n_estimators=100, max_depth=10, min_samples_split=5, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.71, F1-Score: 0.67, ROC-AUC: 0.91, CV Accuracy: 0.78\n",
      "Training Time: 1.50s, Prediction Time: 0.04s\n",
      "Experiment 31/32: n_estimators=100, max_depth=10, min_samples_split=5, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.74, F1-Score: 0.70, ROC-AUC: 0.90, CV Accuracy: 0.78\n",
      "Training Time: 0.99s, Prediction Time: 0.04s\n",
      "Experiment 32/32: n_estimators=100, max_depth=10, min_samples_split=5, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.74, F1-Score: 0.69, ROC-AUC: 0.90, CV Accuracy: 0.78\n",
      "Training Time: 1.01s, Prediction Time: 0.04s\n",
      "\n",
      "Running 32 experiments for n_components=200...\n",
      "Experiment 1/32: n_estimators=50, max_depth=None, min_samples_split=2, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.78, F1-Score: 0.73, ROC-AUC: 0.96, CV Accuracy: 0.80\n",
      "Training Time: 1.59s, Prediction Time: 0.03s\n",
      "Experiment 2/32: n_estimators=50, max_depth=None, min_samples_split=2, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.78, F1-Score: 0.73, ROC-AUC: 0.94, CV Accuracy: 0.79\n",
      "Training Time: 1.36s, Prediction Time: 0.03s\n",
      "Experiment 3/32: n_estimators=50, max_depth=None, min_samples_split=2, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.77, F1-Score: 0.73, ROC-AUC: 0.96, CV Accuracy: 0.80\n",
      "Training Time: 0.84s, Prediction Time: 0.03s\n",
      "Experiment 4/32: n_estimators=50, max_depth=None, min_samples_split=2, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.76, F1-Score: 0.72, ROC-AUC: 0.95, CV Accuracy: 0.80\n",
      "Training Time: 0.78s, Prediction Time: 0.04s\n",
      "Experiment 5/32: n_estimators=50, max_depth=None, min_samples_split=5, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.77, F1-Score: 0.73, ROC-AUC: 0.96, CV Accuracy: 0.80\n",
      "Training Time: 1.51s, Prediction Time: 0.03s\n",
      "Experiment 6/32: n_estimators=50, max_depth=None, min_samples_split=5, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.75, F1-Score: 0.70, ROC-AUC: 0.94, CV Accuracy: 0.80\n",
      "Training Time: 1.41s, Prediction Time: 0.03s\n",
      "Experiment 7/32: n_estimators=50, max_depth=None, min_samples_split=5, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.79, F1-Score: 0.74, ROC-AUC: 0.95, CV Accuracy: 0.80\n",
      "Training Time: 1.00s, Prediction Time: 0.04s\n",
      "Experiment 8/32: n_estimators=50, max_depth=None, min_samples_split=5, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.76, F1-Score: 0.72, ROC-AUC: 0.94, CV Accuracy: 0.80\n",
      "Training Time: 0.80s, Prediction Time: 0.03s\n",
      "Experiment 9/32: n_estimators=50, max_depth=10, min_samples_split=2, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.75, F1-Score: 0.72, ROC-AUC: 0.91, CV Accuracy: 0.77\n",
      "Training Time: 1.00s, Prediction Time: 0.03s\n",
      "Experiment 10/32: n_estimators=50, max_depth=10, min_samples_split=2, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.72, F1-Score: 0.69, ROC-AUC: 0.90, CV Accuracy: 0.77\n",
      "Training Time: 1.00s, Prediction Time: 0.03s\n",
      "Experiment 11/32: n_estimators=50, max_depth=10, min_samples_split=2, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.76, F1-Score: 0.73, ROC-AUC: 0.91, CV Accuracy: 0.77\n",
      "Training Time: 0.70s, Prediction Time: 0.03s\n",
      "Experiment 12/32: n_estimators=50, max_depth=10, min_samples_split=2, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.73, F1-Score: 0.69, ROC-AUC: 0.89, CV Accuracy: 0.76\n",
      "Training Time: 0.56s, Prediction Time: 0.03s\n",
      "Experiment 13/32: n_estimators=50, max_depth=10, min_samples_split=5, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.72, F1-Score: 0.68, ROC-AUC: 0.90, CV Accuracy: 0.77\n",
      "Training Time: 1.04s, Prediction Time: 0.03s\n",
      "Experiment 14/32: n_estimators=50, max_depth=10, min_samples_split=5, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.70, F1-Score: 0.66, ROC-AUC: 0.88, CV Accuracy: 0.78\n",
      "Training Time: 1.00s, Prediction Time: 0.03s\n",
      "Experiment 15/32: n_estimators=50, max_depth=10, min_samples_split=5, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.71, F1-Score: 0.68, ROC-AUC: 0.89, CV Accuracy: 0.75\n",
      "Training Time: 0.67s, Prediction Time: 0.03s\n",
      "Experiment 16/32: n_estimators=50, max_depth=10, min_samples_split=5, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.75, F1-Score: 0.71, ROC-AUC: 0.89, CV Accuracy: 0.75\n",
      "Training Time: 0.58s, Prediction Time: 0.03s\n",
      "Experiment 17/32: n_estimators=100, max_depth=None, min_samples_split=2, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.79, F1-Score: 0.74, ROC-AUC: 0.96, CV Accuracy: 0.82\n",
      "Training Time: 3.00s, Prediction Time: 0.04s\n",
      "Experiment 18/32: n_estimators=100, max_depth=None, min_samples_split=2, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.78, F1-Score: 0.73, ROC-AUC: 0.95, CV Accuracy: 0.81\n",
      "Training Time: 2.80s, Prediction Time: 0.04s\n",
      "Experiment 19/32: n_estimators=100, max_depth=None, min_samples_split=2, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.78, F1-Score: 0.73, ROC-AUC: 0.96, CV Accuracy: 0.81\n",
      "Training Time: 2.50s, Prediction Time: 0.07s\n",
      "Experiment 20/32: n_estimators=100, max_depth=None, min_samples_split=2, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.79, F1-Score: 0.73, ROC-AUC: 0.96, CV Accuracy: 0.81\n",
      "Training Time: 2.58s, Prediction Time: 0.04s\n",
      "Experiment 21/32: n_estimators=100, max_depth=None, min_samples_split=5, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.78, F1-Score: 0.74, ROC-AUC: 0.96, CV Accuracy: 0.82\n",
      "Training Time: 4.21s, Prediction Time: 0.05s\n",
      "Experiment 22/32: n_estimators=100, max_depth=None, min_samples_split=5, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.77, F1-Score: 0.72, ROC-AUC: 0.94, CV Accuracy: 0.81\n",
      "Training Time: 4.94s, Prediction Time: 0.13s\n",
      "Experiment 23/32: n_estimators=100, max_depth=None, min_samples_split=5, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.79, F1-Score: 0.75, ROC-AUC: 0.96, CV Accuracy: 0.81\n",
      "Training Time: 2.54s, Prediction Time: 0.04s\n",
      "Experiment 24/32: n_estimators=100, max_depth=None, min_samples_split=5, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.78, F1-Score: 0.73, ROC-AUC: 0.95, CV Accuracy: 0.82\n",
      "Training Time: 1.57s, Prediction Time: 0.04s\n",
      "Experiment 25/32: n_estimators=100, max_depth=10, min_samples_split=2, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.76, F1-Score: 0.73, ROC-AUC: 0.92, CV Accuracy: 0.77\n",
      "Training Time: 2.05s, Prediction Time: 0.04s\n",
      "Experiment 26/32: n_estimators=100, max_depth=10, min_samples_split=2, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.73, F1-Score: 0.70, ROC-AUC: 0.90, CV Accuracy: 0.77\n",
      "Training Time: 1.98s, Prediction Time: 0.05s\n",
      "Experiment 27/32: n_estimators=100, max_depth=10, min_samples_split=2, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.76, F1-Score: 0.72, ROC-AUC: 0.91, CV Accuracy: 0.77\n",
      "Training Time: 1.13s, Prediction Time: 0.04s\n",
      "Experiment 28/32: n_estimators=100, max_depth=10, min_samples_split=2, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.74, F1-Score: 0.71, ROC-AUC: 0.89, CV Accuracy: 0.77\n",
      "Training Time: 1.16s, Prediction Time: 0.06s\n",
      "Experiment 29/32: n_estimators=100, max_depth=10, min_samples_split=5, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.74, F1-Score: 0.70, ROC-AUC: 0.91, CV Accuracy: 0.77\n",
      "Training Time: 2.03s, Prediction Time: 0.04s\n",
      "Experiment 30/32: n_estimators=100, max_depth=10, min_samples_split=5, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.73, F1-Score: 0.68, ROC-AUC: 0.89, CV Accuracy: 0.78\n",
      "Training Time: 1.99s, Prediction Time: 0.04s\n",
      "Experiment 31/32: n_estimators=100, max_depth=10, min_samples_split=5, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.74, F1-Score: 0.70, ROC-AUC: 0.90, CV Accuracy: 0.76\n",
      "Training Time: 1.15s, Prediction Time: 0.04s\n",
      "Experiment 32/32: n_estimators=100, max_depth=10, min_samples_split=5, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.74, F1-Score: 0.70, ROC-AUC: 0.89, CV Accuracy: 0.76\n",
      "Training Time: 1.11s, Prediction Time: 0.05s\n",
      "\n",
      "Running 32 experiments for n_components=300...\n",
      "Experiment 1/32: n_estimators=50, max_depth=None, min_samples_split=2, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.77, F1-Score: 0.72, ROC-AUC: 0.95, CV Accuracy: 0.78\n",
      "Training Time: 1.93s, Prediction Time: 0.03s\n",
      "Experiment 2/32: n_estimators=50, max_depth=None, min_samples_split=2, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.77, F1-Score: 0.71, ROC-AUC: 0.95, CV Accuracy: 0.79\n",
      "Training Time: 1.75s, Prediction Time: 0.03s\n",
      "Experiment 3/32: n_estimators=50, max_depth=None, min_samples_split=2, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.74, F1-Score: 0.71, ROC-AUC: 0.96, CV Accuracy: 0.78\n",
      "Training Time: 1.00s, Prediction Time: 0.03s\n",
      "Experiment 4/32: n_estimators=50, max_depth=None, min_samples_split=2, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.78, F1-Score: 0.74, ROC-AUC: 0.95, CV Accuracy: 0.78\n",
      "Training Time: 0.96s, Prediction Time: 0.03s\n",
      "Experiment 5/32: n_estimators=50, max_depth=None, min_samples_split=5, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.74, F1-Score: 0.69, ROC-AUC: 0.95, CV Accuracy: 0.79\n",
      "Training Time: 1.83s, Prediction Time: 0.03s\n",
      "Experiment 6/32: n_estimators=50, max_depth=None, min_samples_split=5, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.75, F1-Score: 0.70, ROC-AUC: 0.94, CV Accuracy: 0.79\n",
      "Training Time: 1.79s, Prediction Time: 0.03s\n",
      "Experiment 7/32: n_estimators=50, max_depth=None, min_samples_split=5, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.76, F1-Score: 0.71, ROC-AUC: 0.95, CV Accuracy: 0.77\n",
      "Training Time: 0.95s, Prediction Time: 0.03s\n",
      "Experiment 8/32: n_estimators=50, max_depth=None, min_samples_split=5, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.78, F1-Score: 0.73, ROC-AUC: 0.95, CV Accuracy: 0.78\n",
      "Training Time: 0.93s, Prediction Time: 0.03s\n",
      "Experiment 9/32: n_estimators=50, max_depth=10, min_samples_split=2, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.74, F1-Score: 0.70, ROC-AUC: 0.92, CV Accuracy: 0.75\n",
      "Training Time: 1.28s, Prediction Time: 0.03s\n",
      "Experiment 10/32: n_estimators=50, max_depth=10, min_samples_split=2, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.71, F1-Score: 0.68, ROC-AUC: 0.90, CV Accuracy: 0.75\n",
      "Training Time: 1.24s, Prediction Time: 0.03s\n",
      "Experiment 11/32: n_estimators=50, max_depth=10, min_samples_split=2, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.72, F1-Score: 0.69, ROC-AUC: 0.90, CV Accuracy: 0.75\n",
      "Training Time: 0.65s, Prediction Time: 0.03s\n",
      "Experiment 12/32: n_estimators=50, max_depth=10, min_samples_split=2, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.74, F1-Score: 0.71, ROC-AUC: 0.89, CV Accuracy: 0.74\n",
      "Training Time: 0.64s, Prediction Time: 0.03s\n",
      "Experiment 13/32: n_estimators=50, max_depth=10, min_samples_split=5, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.71, F1-Score: 0.67, ROC-AUC: 0.90, CV Accuracy: 0.74\n",
      "Training Time: 1.24s, Prediction Time: 0.05s\n",
      "Experiment 14/32: n_estimators=50, max_depth=10, min_samples_split=5, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.72, F1-Score: 0.68, ROC-AUC: 0.89, CV Accuracy: 0.76\n",
      "Training Time: 1.36s, Prediction Time: 0.03s\n",
      "Experiment 15/32: n_estimators=50, max_depth=10, min_samples_split=5, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.72, F1-Score: 0.68, ROC-AUC: 0.91, CV Accuracy: 0.73\n",
      "Training Time: 0.70s, Prediction Time: 0.03s\n",
      "Experiment 16/32: n_estimators=50, max_depth=10, min_samples_split=5, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.73, F1-Score: 0.69, ROC-AUC: 0.89, CV Accuracy: 0.74\n",
      "Training Time: 0.65s, Prediction Time: 0.03s\n",
      "Experiment 17/32: n_estimators=100, max_depth=None, min_samples_split=2, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.78, F1-Score: 0.73, ROC-AUC: 0.96, CV Accuracy: 0.80\n",
      "Training Time: 3.53s, Prediction Time: 0.04s\n",
      "Experiment 18/32: n_estimators=100, max_depth=None, min_samples_split=2, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.78, F1-Score: 0.73, ROC-AUC: 0.95, CV Accuracy: 0.80\n",
      "Training Time: 3.47s, Prediction Time: 0.06s\n",
      "Experiment 19/32: n_estimators=100, max_depth=None, min_samples_split=2, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.74, F1-Score: 0.70, ROC-AUC: 0.96, CV Accuracy: 0.80\n",
      "Training Time: 2.41s, Prediction Time: 0.04s\n",
      "Experiment 20/32: n_estimators=100, max_depth=None, min_samples_split=2, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.78, F1-Score: 0.74, ROC-AUC: 0.96, CV Accuracy: 0.80\n",
      "Training Time: 1.82s, Prediction Time: 0.05s\n",
      "Experiment 21/32: n_estimators=100, max_depth=None, min_samples_split=5, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.75, F1-Score: 0.71, ROC-AUC: 0.95, CV Accuracy: 0.80\n",
      "Training Time: 3.57s, Prediction Time: 0.06s\n",
      "Experiment 22/32: n_estimators=100, max_depth=None, min_samples_split=5, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.76, F1-Score: 0.71, ROC-AUC: 0.94, CV Accuracy: 0.80\n",
      "Training Time: 3.46s, Prediction Time: 0.04s\n",
      "Experiment 23/32: n_estimators=100, max_depth=None, min_samples_split=5, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.77, F1-Score: 0.72, ROC-AUC: 0.96, CV Accuracy: 0.79\n",
      "Training Time: 1.87s, Prediction Time: 0.07s\n",
      "Experiment 24/32: n_estimators=100, max_depth=None, min_samples_split=5, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.77, F1-Score: 0.72, ROC-AUC: 0.96, CV Accuracy: 0.79\n",
      "Training Time: 1.86s, Prediction Time: 0.05s\n",
      "Experiment 25/32: n_estimators=100, max_depth=10, min_samples_split=2, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.75, F1-Score: 0.71, ROC-AUC: 0.92, CV Accuracy: 0.76\n",
      "Training Time: 2.42s, Prediction Time: 0.05s\n",
      "Experiment 26/32: n_estimators=100, max_depth=10, min_samples_split=2, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.74, F1-Score: 0.70, ROC-AUC: 0.90, CV Accuracy: 0.78\n",
      "Training Time: 2.42s, Prediction Time: 0.04s\n",
      "Experiment 27/32: n_estimators=100, max_depth=10, min_samples_split=2, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.72, F1-Score: 0.68, ROC-AUC: 0.90, CV Accuracy: 0.74\n",
      "Training Time: 1.53s, Prediction Time: 0.05s\n",
      "Experiment 28/32: n_estimators=100, max_depth=10, min_samples_split=2, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.74, F1-Score: 0.71, ROC-AUC: 0.90, CV Accuracy: 0.76\n",
      "Training Time: 1.28s, Prediction Time: 0.05s\n",
      "Experiment 29/32: n_estimators=100, max_depth=10, min_samples_split=5, max_features=sqrt, min_samples_leaf=1\n",
      "Accuracy: 0.73, F1-Score: 0.69, ROC-AUC: 0.91, CV Accuracy: 0.76\n",
      "Training Time: 2.58s, Prediction Time: 0.04s\n",
      "Experiment 30/32: n_estimators=100, max_depth=10, min_samples_split=5, max_features=sqrt, min_samples_leaf=2\n",
      "Accuracy: 0.73, F1-Score: 0.70, ROC-AUC: 0.90, CV Accuracy: 0.77\n",
      "Training Time: 2.40s, Prediction Time: 0.04s\n",
      "Experiment 31/32: n_estimators=100, max_depth=10, min_samples_split=5, max_features=log2, min_samples_leaf=1\n",
      "Accuracy: 0.76, F1-Score: 0.72, ROC-AUC: 0.91, CV Accuracy: 0.75\n",
      "Training Time: 1.29s, Prediction Time: 0.06s\n",
      "Experiment 32/32: n_estimators=100, max_depth=10, min_samples_split=5, max_features=log2, min_samples_leaf=2\n",
      "Accuracy: 0.73, F1-Score: 0.70, ROC-AUC: 0.90, CV Accuracy: 0.75\n",
      "Training Time: 1.24s, Prediction Time: 0.06s\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Step 4 - Random Forest Experiments\n",
    "def run_rf_experiments(X_train, y_train, X_test, y_test, class_names, n_components):\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [None, 10],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "    total_experiments = np.prod([len(v) for v in param_grid.values()])\n",
    "    print(f\"\\nRunning {total_experiments} experiments for n_components={n_components}...\")\n",
    "    \n",
    "    results = []\n",
    "    experiment_count = 0\n",
    "    \n",
    "    for n_estimators in param_grid['n_estimators']:\n",
    "        for max_depth in param_grid['max_depth']:\n",
    "            for min_samples_split in param_grid['min_samples_split']:\n",
    "                for max_features in param_grid['max_features']:\n",
    "                    for min_samples_leaf in param_grid['min_samples_leaf']:\n",
    "                        experiment_count += 1\n",
    "                        print(f\"Experiment {experiment_count}/{total_experiments}: n_estimators={n_estimators}, max_depth={max_depth}, min_samples_split={min_samples_split}, max_features={max_features}, min_samples_leaf={min_samples_leaf}\")\n",
    "                        \n",
    "                        rf_classifier = RandomForestClassifier(\n",
    "                            n_estimators=n_estimators,\n",
    "                            max_depth=max_depth,\n",
    "                            min_samples_split=min_samples_split,\n",
    "                            max_features=max_features,\n",
    "                            min_samples_leaf=min_samples_leaf,\n",
    "                            random_state=42,\n",
    "                            class_weight='balanced',\n",
    "                            n_jobs=-1\n",
    "                        )\n",
    "                        \n",
    "                        start_time = time.time()\n",
    "                        rf_classifier.fit(X_train, y_train)\n",
    "                        training_time = time.time() - start_time\n",
    "                        \n",
    "                        start_time = time.time()\n",
    "                        predictions = rf_classifier.predict(X_test)\n",
    "                        prediction_time = time.time() - start_time\n",
    "                        \n",
    "                        accuracy = accuracy_score(y_test, predictions)\n",
    "                        f1 = f1_score(y_test, predictions, average='weighted')\n",
    "                        roc_auc = roc_auc_score(y_test, rf_classifier.predict_proba(X_test), multi_class='ovr')\n",
    "                        \n",
    "                        cv_scores = cross_val_score(rf_classifier, X_train, y_train, cv=5, scoring='accuracy')\n",
    "                        cv_accuracy = np.mean(cv_scores)\n",
    "                        \n",
    "                        results.append({\n",
    "                            'n_components': n_components,\n",
    "                            'n_estimators': n_estimators,\n",
    "                            'max_depth': max_depth,\n",
    "                            'min_samples_split': min_samples_split,\n",
    "                            'max_features': max_features,\n",
    "                            'min_samples_leaf': min_samples_leaf,\n",
    "                            'accuracy': accuracy,\n",
    "                            'f1_score': f1,\n",
    "                            'roc_auc': roc_auc,\n",
    "                            'cv_accuracy': cv_accuracy,\n",
    "                            'training_time': training_time,\n",
    "                            'prediction_time': prediction_time\n",
    "                        })\n",
    "                        \n",
    "                        print(f\"Accuracy: {accuracy:.2f}, F1-Score: {f1:.2f}, ROC-AUC: {roc_auc:.2f}, CV Accuracy: {cv_accuracy:.2f}\")\n",
    "                        print(f\"Training Time: {training_time:.2f}s, Prediction Time: {prediction_time:.2f}s\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "all_results = []\n",
    "results_path = os.path.join(output_dir, \"rf_results_all_pca.csv\")\n",
    "\n",
    "if os.path.exists(results_path):\n",
    "    print(\"Loading saved experiment results...\")\n",
    "    all_results = pd.read_csv(results_path).to_dict('records')\n",
    "else:\n",
    "    for n_components in n_components_list:\n",
    "        X_train_pca, X_test_pca = pca_data[n_components]\n",
    "        results = run_rf_experiments(X_train_pca, y_train, X_test_pca, y_test, class_names, n_components)\n",
    "        all_results.extend(results)\n",
    "        pd.DataFrame(all_results).to_csv(results_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined Results for All PCA Settings:\n",
      "    n_components  n_estimators  max_depth  min_samples_split max_features  \\\n",
      "0            100            50        NaN                  2         sqrt   \n",
      "1            100            50        NaN                  2         sqrt   \n",
      "2            100            50        NaN                  2         log2   \n",
      "3            100            50        NaN                  2         log2   \n",
      "4            100            50        NaN                  5         sqrt   \n",
      "..           ...           ...        ...                ...          ...   \n",
      "91           300           100       10.0                  2         log2   \n",
      "92           300           100       10.0                  5         sqrt   \n",
      "93           300           100       10.0                  5         sqrt   \n",
      "94           300           100       10.0                  5         log2   \n",
      "95           300           100       10.0                  5         log2   \n",
      "\n",
      "    min_samples_leaf  accuracy  f1_score   roc_auc  cv_accuracy  \\\n",
      "0                  1  0.751269  0.704069  0.950897     0.815679   \n",
      "1                  2  0.751269  0.705256  0.932280     0.815331   \n",
      "2                  1  0.774112  0.728437  0.945663     0.812195   \n",
      "3                  2  0.753807  0.701479  0.947438     0.821603   \n",
      "4                  1  0.779188  0.728299  0.945739     0.812892   \n",
      "..               ...       ...       ...       ...          ...   \n",
      "91                 2  0.743655  0.712553  0.897797     0.756098   \n",
      "92                 1  0.733503  0.694623  0.905568     0.759233   \n",
      "93                 2  0.733503  0.697506  0.896703     0.765157   \n",
      "94                 1  0.758883  0.722359  0.908281     0.745993   \n",
      "95                 2  0.728426  0.696010  0.900458     0.748432   \n",
      "\n",
      "    training_time  prediction_time  \n",
      "0        2.527530         0.061763  \n",
      "1        1.092025         0.029328  \n",
      "2        0.683109         0.027264  \n",
      "3        0.680685         0.026324  \n",
      "4        1.063075         0.027813  \n",
      "..            ...              ...  \n",
      "91       1.282913         0.050250  \n",
      "92       2.581676         0.038643  \n",
      "93       2.396780         0.038719  \n",
      "94       1.294046         0.055161  \n",
      "95       1.239804         0.055005  \n",
      "\n",
      "[96 rows x 12 columns]\n",
      "\n",
      "Classification Report for Best Model:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    glioma_tumor       0.92      0.24      0.38       100\n",
      "meningioma_tumor       0.72      0.99      0.83       115\n",
      "        no_tumor       0.83      1.00      0.91       105\n",
      " pituitary_tumor       0.84      0.93      0.88        74\n",
      "\n",
      "        accuracy                           0.79       394\n",
      "       macro avg       0.83      0.79      0.75       394\n",
      "    weighted avg       0.82      0.79      0.75       394\n",
      "\n",
      "\n",
      "Kaggle submission saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Step 5 - Visualize and Save Results\n",
    "def visualize_and_save_results(all_results, X_train, y_train, X_test, y_test, class_names):\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    print(\"\\nCombined Results for All PCA Settings:\")\n",
    "    print(results_df)\n",
    "    \n",
    "    results_df.to_csv(os.path.join(output_dir, \"rf_results_all_pca.csv\"), index=False)\n",
    "    \n",
    "    best_idx = results_df['accuracy'].idxmax()\n",
    "    max_depth = results_df.loc[best_idx]['max_depth']\n",
    "    max_depth = None if pd.isna(max_depth) else int(max_depth)\n",
    "    \n",
    "    best_rf = RandomForestClassifier(\n",
    "        n_estimators=int(results_df.loc[best_idx]['n_estimators']),\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=int(results_df.loc[best_idx]['min_samples_split']),\n",
    "        max_features=results_df.loc[best_idx]['max_features'],\n",
    "        min_samples_leaf=int(results_df.loc[best_idx]['min_samples_leaf']),\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    n_components = int(results_df.loc[best_idx]['n_components'])\n",
    "    X_train_pca, X_test_pca = pca_data[n_components]\n",
    "    best_rf.fit(X_train_pca, y_train)\n",
    "    predictions = best_rf.predict(X_test_pca)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Best Random Forest Confusion Matrix')\n",
    "    plt.savefig(os.path.join(output_dir, 'rf_confusion_matrix_best.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nClassification Report for Best Model:\")\n",
    "    print(classification_report(y_test, predictions, target_names=class_names))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=results_df, x='n_estimators', y='accuracy', hue='n_components', style='max_depth')\n",
    "    plt.title('Accuracy vs. n_estimators by PCA Components')\n",
    "    plt.savefig(os.path.join(output_dir, 'rf_accuracy_vs_estimators_pca.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=results_df, x='max_features', y='accuracy', hue='n_components', style='min_samples_leaf')\n",
    "    plt.title('Accuracy vs. max_features by PCA Components')\n",
    "    plt.savefig(os.path.join(output_dir, 'rf_accuracy_vs_max_features_pca.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    test_ids = [f\"test_{i}\" for i in range(len(y_test))]\n",
    "    submission_df = pd.DataFrame({'id': test_ids, 'predicted_class': [class_names[p] for p in predictions]})\n",
    "    submission_df.to_csv(os.path.join(output_dir, 'submission.csv'), index=False)\n",
    "    print(\"\\nKaggle submission saved as 'submission.csv'\")\n",
    "\n",
    "visualize_and_save_results(all_results, X_train, y_train, X_test, y_test, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holdout vs. Cross-Validation Comparison:\n",
      "    n_components  n_estimators  max_depth  accuracy  cv_accuracy\n",
      "0            100            50        NaN  0.751269     0.815679\n",
      "1            100            50        NaN  0.751269     0.815331\n",
      "2            100            50        NaN  0.774112     0.812195\n",
      "3            100            50        NaN  0.753807     0.821603\n",
      "4            100            50        NaN  0.779188     0.812892\n",
      "..           ...           ...        ...       ...          ...\n",
      "91           300           100       10.0  0.743655     0.756098\n",
      "92           300           100       10.0  0.733503     0.759233\n",
      "93           300           100       10.0  0.733503     0.765157\n",
      "94           300           100       10.0  0.758883     0.745993\n",
      "95           300           100       10.0  0.728426     0.748432\n",
      "\n",
      "[96 rows x 5 columns]\n",
      "\n",
      "Average Accuracy Difference (Holdout - CV):\n",
      "n_components\n",
      "100   -0.050969\n",
      "200   -0.029131\n",
      "300   -0.023125\n",
      "Name: accuracy_diff, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Step 6 - Compare Holdout vs. Cross-Validation\n",
    "results_df = pd.DataFrame(all_results)\n",
    "print(\"\\nHoldout vs. Cross-Validation Comparison:\")\n",
    "print(results_df[['n_components', 'n_estimators', 'max_depth', 'accuracy', 'cv_accuracy']])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=results_df, x='accuracy', y='cv_accuracy', hue='n_components', size='n_estimators')\n",
    "plt.plot([results_df['accuracy'].min(), results_df['accuracy'].max()], \n",
    "         [results_df['accuracy'].min(), results_df['accuracy'].max()], 'k--')\n",
    "plt.title('Holdout Accuracy vs. Cross-Validation Accuracy')\n",
    "plt.xlabel('Holdout Accuracy')\n",
    "plt.ylabel('Cross-Validation Accuracy')\n",
    "plt.savefig(os.path.join(output_dir, 'holdout_vs_cv_accuracy.png'))\n",
    "plt.close()\n",
    "\n",
    "results_df['accuracy_diff'] = results_df['accuracy'] - results_df['cv_accuracy']\n",
    "print(\"\\nAverage Accuracy Difference (Holdout - CV):\")\n",
    "print(results_df.groupby('n_components')['accuracy_diff'].mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
